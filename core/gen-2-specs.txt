# The specifications for gen-2.py start here.

Modify the above gen-1.py script to implement the following requirements:
- Single required parameter is a YAML file containing top-level 'tasks:' holding list of tasks. Loop over tasks. Each task will specify the YAML keys listed below and will behave similar to the original gen-1 main(), with modifications described below.
- 'hardcoded:' list containing path/content pairs to be written as-is, relative to output-dir. Process these before the inputs.
- 'inputs:' lists the input files, supporting '-' for stdin
- 'prompt:' is additional prompt material added to the top.
- 'lang:' key will specify the generation language, denoted by its common file extension, defaulting to 'py'
- 'output-dir:' indicating where files will be written.
- 'max-retries:' default 3
- 'pipeline:' list of steps in format { subprocess: [ exe, param... ]}

Create a common system prompt generator which can be used for initial implementation and for fixes:
    """Generate complete implementation files based on requirements (or error information, for fixes).
    Return JSON in this format:
    {
      "overview": "... explain the approach, and justification for modifying the files below ..."
      "files": [
        {"path": "relative/path/file1.ext", "content": "complete file contents"},
        {"path": "relative/path/file2.ext", "content": ""}
      ]
    }
    For large or complex files, leave "content" empty to be generated later.
    List all necessary files to meet requirements, include content if small enough."""
Implement a common function that can interpret and execute output in the above format:

- For each task: Call chat.invoke() with the above prompt. Log the output to stderr. Parse the JSON output. If JSON is invalid, call LLM again with modified version of prompt, this time remove the `content` field completely. Then, process each item in `files`. Call os.makedirs(..., exist_ok=True) to ensure dir path exists. Ask LLM to generate content if missing. Write out each file contents.

- Finally, after all tasks have been completed: execute the pipeline. Prepare a system prompt similar to the above, with the additional instruction: "The pipeline is failing with the following errors, please provide a plan to fix it: {errors}". With this prompt, execute chat.invoke() follow the same process as above to re-create the files. Once files are modified, go back to the first step of the pipeline.

- Repeat the pipeline/fix cycle until all steps are successful, or max-retries.

- When gen-2.py is executed without any arguments, it must perform a self-test of the code integrity, similar to a unit test, but less intrusive and focused only on a single happy-path scenario:
   - Log "self-test started" to stderr.
   - Invoke `python sys.argv[0] [yaml_path]` where yaml file contains 'tasks:' with inputs: [ "-" ], output-dir: ./testdata, max-retries:1, pipeline: [ { subprocess: [python, validator.py]}] in a subprocess with this prompt passed to stdin: "write a main.py that prints the largest prime number under 100, number only, and a validator.py that invokes main.py and only exits successfully if the output of main.py is correct"
   - All output lines from the self-test must be prefixed by 'TEST: ' when logged, to avoid confusion. Log them to stderr. For ease of debugging, these prefixed logs must include the config file used, the prompts used in the test, and the code generated in the test. 
   - The self-test is successful only if the nested gen-2.py invocation returns successfully.

Technical requirements:
- Maintain a single chat session object for each task run, this removes the need to repeat parts of a prompt in later prompts.
- chat.invoke(user_prompt, filetype, system_prompt=None) has two required parameters and one optional. Always pass the file extension as the filetype if available, otherwise, default to "text". Always invoke with explicit named parameters for clarity.
- Header comment "# Generated by AI" followed by explanation, usage, yaml format, and Change Log (start: v0.1).
- Update the Change Log based on your review of earlier messages in the chat history.
- The self-test must exit(1) on failure and print details to assist debugging
- DO NOT skip initialization in any execution path
- All test files should be in the specified output dir. Do not create files in the CWD.
- Always generate complete code files. Do not use placeholders like "[Previous code content remains exactly the same until X]". Repeat the entire file contents each time to ensure completeness and avoid confusion.
- Use extra-short variable and function names to save on tokens.
- Use `in` or `get` to avoid KeyError when missing key is allowed.
- Use assert() extensively to check value types and ranges.
- Close temp file before subprocess to avoid PermissionError.
- Log verbosely: before/after LLM calls, before file IO, before/after subprocess invocation.
- Log all captured subprocess stdout/stderr output to our stderr, with a prefix on each line for clarity.
