vision: >

  Poodah (Hadoop spelled backwards) is an AWS-native runtime for Map Reduce jobs.
  It also rhymes with Poodle, a type of small, ugly dog.

  Goals:
  - Completely serverless (scale-to-zero, no recurring fees for idle compute resources)
  - High degree of parallel execution
  - Efficient incremental updates (avoid unnecessary re-computation)
  - Simple AWS operations
  - Hadoop-compatible Java APIs
  - One-line deploy using standard SAM CLI: "sam deploy"

  Simplifying assumptions:
  - S3 in, S3 out, JSON only. 
  - No concept of a "job" - just process the files in the given s3/path as they arrive
  - Use DynamoDB for intermediate results. Use dynamo stream to trigger the reduce step.
  - Consume from S3 in large batches of multiple objects, to minimize churn over intermediate results.
  - Incremental processing is via S3 SNS trigger; full re-process is a manual trigger via AWS CLI.
  - Leverage SAM to create the S3 bucket, SNS triggers, Lambdas, and CI/CD pipelines.
  - 100% Java
  - The Mapper and Reducer are wrapped in Lambda Functions
  - AWS Lambda's automated retry mechanism is sufficient for our purposes
  - CloudWatch is sufficient for logging, alerting, etc
  - S3 and Lambda provide all needed scalability
  - Security is at the AWS account level.
  - There will be no user interaction: data lands in S3 and gets processed.
  - Unit-testing target 85% Code Coverage.
  - No encryption beyond what's already provided by default
  - No special handling for large files

  Detailed technical specifications - include these verbatim in the revised vision:
  - Java version: 17
  - AWS Java SDK Version: 2.26.8
  - Relevant Hadoop APIs:
          Class Mapper<KEYIN,VALUEIN,KEYOUT,VALUEOUT> ...
          public void map(Object key, Text value, Context context);
          Class Reducer<KEYIN,VALUEIN,KEYOUT,VALUEOUT> ...
          public void reduce(KEYIN key, Iterable<VALUEIN> values, org.apache.hadoop.mapreduce.Reducer.Context context);
  - Build the Java using mvn before invoking sam deploy

tasks:
  - prompt: >
      Please generate the project's README.md file. 
      Assume that everything described in the vision has been implemented.
      Write in the style of an IBM manual. License is GPLv3 with no free support.
    target: OVERVIEW.md

  - prompt: >
      You are the lead architect for this project. 
      Generate a list of questions for the product owner.
      Generate a preferred or presumed answer based on the vision statement.
      Assume a high degree of confidence in each answer, as if the answer blindingly obvious, but keep it professional and avoid sarcasm.
      Format it as a FAQ. Skip the pleasantries and start with the document title.
    target: architecture-faq.md

  - prompt: >
      Please generate the complete list of files to implement the project.
      This should be in YAML format as the key 'tasks:' which defines a list of 
        prompt: the technical specifications for generating the file contents
        target: the name of the output file
        import: [ "file1", "file2", ... ] context for the developer to review while working.
      Start with a technical specification under the 'vision: |' key before the tasklist.
      The output must be valid yaml.
      Do not write anything before the YAML. Fold explanations into the vision.
      The vision must include a description of how the various classes interact, including,
      any interfaces and method signatures.
      The vision must specify the programming language.
      Output the tasks in import-aware order, without dependencies on future files.
    target: development_tasks.yaml

  - prompt: >
      You are the Lead Developer for this project and you're trying to cleanup the mess
      left behind by the Junior Developer who wrote all the code without running even a
      single build.
      Using the provided LLM script as a base, remove the YAML parsing part, and generate
      a new script which will use the LLM to automatically troubleshoot and fix code on your behalf.
      Do not add new dependencies.
      The generated program should work as follows:
      - start by executing a `chdir ai-outputs/`, 
      - then `docker build -t dev .`, 
      - Feed the docker output to LLM Call #1 to identify all files that need to be reviewed.
      - Loop over the files identified by the LLM in Call #1.
      - For each file, make LLM Call #2, asking to suggest fixes, passing the following as context: the file, the Docker output, the Dockerfile, and the project definition YAML. 
      - Ask the human to review the suggested changes. When taking human input, Enter means approval, q to abort, any other response is taken as further instructions to be passed back to the LLM to adjust the output from the previous step.
      - Repeat until fixed.

    import: [generator.py]
    target: debug-fix.py

  - prompt: >
      You had to step up as a DevOps Engineer.
      Generate the SAM/Java Docker build using the AWS image: 
        public.ecr.aws/sam/build-python3.12:latest
      This image uses dnf for packages, not yum.
      Do something to ensure the Maven packages are not re-downloaded every time.
      If you need a settings.xml, create it yourself. Do not try "COPY settings.xml".
      Make the "mvn dependency:go-offline" line completely silent.
    target: Dockerfile
